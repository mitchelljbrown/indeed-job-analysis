[
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "About This Project",
    "section": "Motivation",
    "text": "Motivation\nAs an aspiring data analyst, I am interested in the job prospects of this career in Canada and gain insight on the location of most of the jobs, their pay, and the rating employees give to their companies. Indeed.ca is a great place to find this information. I decided to scrape data form indeed.ca with python, and then clean the data and analyze it in R. This website presents my scraping, cleaning, and visualization methods in a clear and concise way. I hope you enjoy learning about my process and find the analysis interesting"
  },
  {
    "objectID": "indeed-scraping.html",
    "href": "indeed-scraping.html",
    "title": "Data Analyst Job Insights in Canada",
    "section": "",
    "text": "import csv\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport requests\nimport datetime as dt"
  },
  {
    "objectID": "indeed-scraping.html#navigate-to-website",
    "href": "indeed-scraping.html#navigate-to-website",
    "title": "Data Analyst Job Insights in Canada",
    "section": "Navigate To Website",
    "text": "Navigate To Website\n\n# get to indeed.com\n\ndef get_soup(url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/537.36',\n        'Accept-Language': 'en-US,en;q=0.9',\n        'DNT': '1'\n    }\n\n    page = requests.get(url, headers=headers)\n\n    # create soup record\n    soup = BeautifulSoup(page.content, 'html.parser')\n    # records = soup.find_all('td', class_='resultContent')\n    return soup"
  },
  {
    "objectID": "indeed-scraping.html#create-function-to-extract-records",
    "href": "indeed-scraping.html#create-function-to-extract-records",
    "title": "Data Analyst Job Insights in Canada",
    "section": "Create Function to Extract Records",
    "text": "Create Function to Extract Records\n\ndef get_record(record):\n\n    title = record.h2.text\n    company = record.find('span', class_='companyName').text\n    location = record.find('div', class_='companyLocation').text\n\n    # extract pay information if it exists\n    try:\n        pay = record.find('div', class_='metadata salary-snippet-container').text\n    except AttributeError:\n        pay = ''\n\n    # extract rating informaiton if it extists\n    try:\n        rating = record.find('span', {'aria-hidden': 'true'}).text\n    except AttributeError:\n        rating = ''\n\n    result = (title, company, location, pay, rating)\n\n    return result"
  },
  {
    "objectID": "indeed-scraping.html#collect-records-from-all-pages",
    "href": "indeed-scraping.html#collect-records-from-all-pages",
    "title": "Data Analyst Job Insights in Canada",
    "section": "Collect Records From All Pages",
    "text": "Collect Records From All Pages\n\ndef scrape(url):\n    \n    soup = get_soup(url)\n    data = []\n    while True:\n        try:\n            url = 'https://ca.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')\n        except AttributeError:\n            break\n\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        records = soup.find_all('td', class_='resultContent')\n\n        for card in records:\n            record = get_record(card)\n            data.append(record)\n\n    return pd.DataFrame(data)\n\n\n\ndf1 = scrape('https://ca.indeed.com/jobs?q=geologist&l&vjk=7dc5bc08dd5403df')\ndf1['job'] = 'Geologist'\ndf2 = scrape('https://ca.indeed.com/jobs?q=data%20analyst&l&vjk=d5c29d10430b1346')\ndf2['job'] = 'Data Analyst'\n\ndata = df1.append(df2)\n\n\ndata\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      job\n    \n  \n  \n    \n      0\n      newData Analyst - Geophysics\n      Sander Geophysics Limited\n      Ottawa, ON\n      \n      3.8\n      Geologist\n    \n    \n      1\n      newCore Logging Geologist (Remote Camp)\n      Workforce Inc.\n      Timmins, ON\n      $34–$40 an hour\n      4.6\n      Geologist\n    \n    \n      2\n      mine geologist\n      SLR Consulting (Canada) Ltd.\n      Toronto, ON\n      $120,000–$145,000 a year\n      3.7\n      Geologist\n    \n    \n      3\n      newProject Geologist\n      Fladgate Exploration Consulting Corporation\n      Thunder Bay, ON\n      \n      \n      Geologist\n    \n    \n      4\n      Geological Technician/Jr Geologist\n      Healthcare Systems R & A Inc.\n      Montréal, QC\n      $24–$35 an hour\n      \n      Geologist\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      955\n      Intermediate Business Analyst, HR SW & Reporting\n      Procom\n      Toronto, ON\n      \n      3.6\n      Data Analyst\n    \n    \n      956\n      newBusiness Analyst (Trading, Capital Markets,...\n      Teamrecruiter.com\n      Toronto, ON\n      \n      \n      Data Analyst\n    \n    \n      957\n      Infrastructure Business Analyst\n      TES - The Employment Solution\n      Regina, SK\n      \n      3.6\n      Data Analyst\n    \n    \n      958\n      newSenior Business Analyst\n      Procom\n      Toronto, ON\n      \n      3.6\n      Data Analyst\n    \n    \n      959\n      newProject Manager Business Intelligence - Nor...\n      Randstad\n      North York, ON\n      \n      3.7\n      Data Analyst\n    \n  \n\n1205 rows × 6 columns"
  },
  {
    "objectID": "indeed-scraping.html#create-pandas-data.frame",
    "href": "indeed-scraping.html#create-pandas-data.frame",
    "title": "Data Analyst Job Insights in Canada",
    "section": "Create Pandas Data.Frame",
    "text": "Create Pandas Data.Frame\n\n# covert to DataFrame\ndf = data\n\n# set columns\ndf.columns = [\"title\", \"company\", \"location\", \"pay\", \"rating\", \"job\"]\n\n# file name\nfname = \"job-data\" + dt.datetime.today().strftime('%Y-%m-%d') + '.csv'\n\n# save to .csv\ndf.to_csv(fname)\n\n# print first 5 rows of data\ndf.head()\n\n\n\n\n  \n    \n      \n      title\n      company\n      location\n      pay\n      rating\n      job\n    \n  \n  \n    \n      0\n      newData Analyst - Geophysics\n      Sander Geophysics Limited\n      Ottawa, ON\n      \n      3.8\n      Geologist\n    \n    \n      1\n      newCore Logging Geologist (Remote Camp)\n      Workforce Inc.\n      Timmins, ON\n      $34–$40 an hour\n      4.6\n      Geologist\n    \n    \n      2\n      mine geologist\n      SLR Consulting (Canada) Ltd.\n      Toronto, ON\n      $120,000–$145,000 a year\n      3.7\n      Geologist\n    \n    \n      3\n      newProject Geologist\n      Fladgate Exploration Consulting Corporation\n      Thunder Bay, ON\n      \n      \n      Geologist\n    \n    \n      4\n      Geological Technician/Jr Geologist\n      Healthcare Systems R & A Inc.\n      Montréal, QC\n      $24–$35 an hour\n      \n      Geologist"
  },
  {
    "objectID": "cleaning.html#cleaning",
    "href": "cleaning.html#cleaning",
    "title": "Cleaning Indeed Data",
    "section": "Cleaning",
    "text": "Cleaning\nMost of the columns scraped here are in good condition to start using. However, the pay column is currently in string format, and contains additional strings as well as ranges of salaries. The strings will need to be parsed and the numeric values extracted. To deal with salary ranges, the average of the range will be taken so we can represent pay as a single number\n\nOriginal Scraped Data\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\ncompany\nlocation\npay\nrating\n\n\n\n\nnewJunior Data Analyst\nAppleOne\nMississauga, ON\n$45,800 a year\n3.8\n\n\nData Analyst (Remote in Canada)\nInteraxon\nRemote in Toronto, ON\n$80,000 - $110,000 a year\nNA\n\n\nnewData Analyst (VBA,SQL)\nSun Life Financial\nTemporarily Remote in Toronto, ON\n\n3.9\n\n\nData Analyst/ Data Engineer/ Datawarehouse Analyst\nShorewise Consulting LLC\nRemote in Mississauga, ON\n$47 an hour\nNA\n\n\nData Analyst - Level 3\nLibro Credit Union\nLondon, ON\n\n3.7\n\n\n\n\n\n\n\nCreating a new location column\nMany data analyst positions are remote. Many of the listings still contain the city where the company is based with the word “remote” somewhere in the location such as “Remote in Toronto, ON”. If we want to analyze this data based on whether positions are remote or not, it would be nice if the location column was categorical and every position with remote in the title could be grouped into one. Therefor, if a column contains “remote” or “Remote”, the string will be changed to “remote” in the location column.\n\n# return remote location if remote is found in title\ndata[, location := ifelse(grepl(\"Remote\", title) | grepl(\"Remote\", location)|\n                         grepl(\"remote\", title) | grepl(\"remote\", location),\n                         \"remote\", location)]\n\nkable(head(data, 5))\n\n\n\n\n\n\n\n\n\n\n\ntitle\ncompany\nlocation\npay\nrating\n\n\n\n\nnewJunior Data Analyst\nAppleOne\nMississauga, ON\n$45,800 a year\n3.8\n\n\nData Analyst (Remote in Canada)\nInteraxon\nremote\n$80,000 - $110,000 a year\nNA\n\n\nnewData Analyst (VBA,SQL)\nSun Life Financial\nremote\n\n3.9\n\n\nData Analyst/ Data Engineer/ Datawarehouse Analyst\nShorewise Consulting LLC\nremote\n$47 an hour\nNA\n\n\nData Analyst - Level 3\nLibro Credit Union\nLondon, ON\n\n3.7\n\n\n\n\n\n\n\nCreating A Province Column\nIf we want to organize jobs by province, we can parse the last two characters from the location column where the column != “remote” and matches one of the provinces from the list of province abbreviations provided.\n\n# create a province column that takes the location column and splits the column into a list of strings\ndata[, province := ifelse(length(strsplit(location, \" \")) > 1, \n                          strsplit(location, \" \"),\n                          strsplit(location, \" \"))]\n\n# take the last two characters from the last word in the list\ndata[, province := ifelse(location != \"remote\", toupper(str_sub(location,-2)),\n                          \"remote\")]\n\nkable(head(data, 5))\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\ncompany\nlocation\npay\nrating\nprovince\n\n\n\n\nnewJunior Data Analyst\nAppleOne\nMississauga, ON\n$45,800 a year\n3.8\nON\n\n\nData Analyst (Remote in Canada)\nInteraxon\nremote\n$80,000 - $110,000 a year\nNA\nremote\n\n\nnewData Analyst (VBA,SQL)\nSun Life Financial\nremote\n\n3.9\nremote\n\n\nData Analyst/ Data Engineer/ Datawarehouse Analyst\nShorewise Consulting LLC\nremote\n$47 an hour\nNA\nremote\n\n\nData Analyst - Level 3\nLibro Credit Union\nLondon, ON\n\n3.7\nON\n\n\n\n\n\n\n\nCleaning the Pay Column\nThe pay column presents some hurtles to overcome to extract numeric information. This is my process for doing so\n\n# remove commas\ndata$pay <- gsub(\",\", \"\", data$pay)\n\n# extract only numbers from pay\ndata[, pay_extract := regmatches(pay, gregexpr(\"[[:digit:]]+\", pay))]\n\nkable(head(data, 5))\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\ncompany\nlocation\npay\nrating\nprovince\npay_extract\n\n\n\n\nnewJunior Data Analyst\nAppleOne\nMississauga, ON\n$45800 a year\n3.8\nON\n45800\n\n\nData Analyst (Remote in Canada)\nInteraxon\nremote\n$80000 - $110000 a year\nNA\nremote\n80000 , 110000\n\n\nnewData Analyst (VBA,SQL)\nSun Life Financial\nremote\n\n3.9\nremote\n\n\n\nData Analyst/ Data Engineer/ Datawarehouse Analyst\nShorewise Consulting LLC\nremote\n$47 an hour\nNA\nremote\n47\n\n\nData Analyst - Level 3\nLibro Credit Union\nLondon, ON\n\n3.7\nON\n\n\n\n\n\n\n\n# split pay into 2 columns\n# if there are two numbers (salary range), low number will be in the first column, high in second column\n# if there is one number, the number will be in the first column and \"NA\" in the second\n\ndata <- data %>% unnest_wider(pay_extract)\ndata <- data.table(data)\n\n# remove unwanted columns generated with \"unnest_wider\"\ndata[, c(\"...3\",\"...4\") := NULL]\n\n# change column names\ncolnames(data)[7:8] <- c(\"low\", \"high\")\n\n# make columns numeric \ndata$high <- as.numeric(data$high)\ndata$low <- as.numeric(data$low)\n\n# reformat null values as some are not readable\ndata[, rating := ifelse(rating == \"NA\", NA, rating)]\n\n# make a column for average pay\ndata[, average := ifelse(is.na(high), low, (high + low)/2)]\n\n# get rid of original pay column\ndata[, pay := NULL]\n\n# only include relevant columns\ndata <- data[, c(\"title\", \"company\", \"location\", \"rating\", \"province\", \"average\")]\n\n# change \"average\"average\" column as the new \"pay\" column\ncolnames(data)[length(colnames(data))] <- \"pay\"\n\n\n\nNow this is what our cleaned data looks like"
  },
  {
    "objectID": "visualizing.html#data",
    "href": "visualizing.html#data",
    "title": "Visualizing Cleaned Data",
    "section": "Data",
    "text": "Data\nThis is what the data looks like after it has been cleaned. Using the “DT” package the data can be sifted and searched in this table\n\n\n\n\n\n\n\nAdd Boolean “remote” Column and Account for Hydrogeologists\nHydrogeologists make up a portion of total Geologist Jobs. If the job title in the Geology Jobs contains the word “hydrogeologist”, the “job” column will be changed from “geologist” to “hydrogeologist” to compare the difference between these professions in the field of Hydrogeology.\n\n# Split into two data.tables for individual analysis\nanalyst <- data[job == \"Data Analyst\"]\ngeologist <- data[job == \"Geologist\"]\n\n# if the title contains the word \"hydrogeologist\", change the job column to \"hydrogeologist\"\ngeologist <- geologist[, job := ifelse(title %like% \"hydrogeologist\" | title %like% \"Hydrogeologist\", \"Hydrogeologist\", job)]\n\n\n\nData Summary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nV1\ntitle\ncompany\nlocation\nrating\nprovince\npay\njob\nremote\n\n\n\n\n\nMin. : 1.0\nLength:1110\nLength:1110\nLength:1110\nMin. :1.500\nLength:1110\nMin. : 500\nLength:1110\nMode :logical\n\n\n\n1st Qu.: 278.2\nClass :character\nClass :character\nClass :character\n1st Qu.:3.500\nClass :character\n1st Qu.: 57500\nClass :character\nFALSE:838\n\n\n\nMedian : 555.5\nMode :character\nMode :character\nMode :character\nMedian :3.750\nMode :character\nMedian : 74000\nMode :character\nTRUE :272\n\n\n\nMean : 555.5\nNA\nNA\nNA\nMean :3.685\nNA\nMean : 74986\nNA\nNA\n\n\n\n3rd Qu.: 832.8\nNA\nNA\nNA\n3rd Qu.:3.900\nNA\n3rd Qu.: 92078\nNA\nNA\n\n\n\nMax. :1110.0\nNA\nNA\nNA\nMax. :5.000\nNA\nMax. :212750\nNA\nNA\n\n\n\nNA\nNA\nNA\nNA\nNA’s :330\nNA\nNA’s :917\nNA\nNA\n\n\n\n\n\n\n\nMissing Values Distribution\nMost companies on indeed don not provide pay information. In fact, we are only 32.52 jobs provide information regarding pay.\nMany employees rate their companies however. Only 32% of companies do not have ratings"
  },
  {
    "objectID": "visualizing.html#pay-distribution",
    "href": "visualizing.html#pay-distribution",
    "title": "Visualizing Cleaned Data",
    "section": "Pay Distribution",
    "text": "Pay Distribution\n\nAll JobsData AnalystGeologist\n\n\n\n\nCode\n# remove values below $20000 (values that fall within the $100-$20000 must be contract poitions and were not accoutned for when cleaing)\npay_distribution <- data[pay > 20000]\n\nggplot(pay_distribution, aes(job, pay)) +\n  geom_violin(aes(color=job)) +\n  geom_beeswarm(aes(color=job)) +\n  labs(title = \"Pay Distribution Between Data Analyst and Geology Jobs\",\n       y = \"Yearly Salary (CAD)\")\n\n\n\n\n\n\n\n\n\nCode\npay_distribution_analyst <- analyst[pay > 20000]\n\nggplot(pay_distribution_analyst, aes(remote, pay)) +\n  geom_violin(aes(color=remote)) +\n  geom_beeswarm(aes(color =remote)) +\n  labs(title = \"Pay Distribution Between Remote and Non-Remote Data Analyst Jobs\",\n       y = \"Yearly Salary (CAD)\")\n\n\n\n\n\n\n\n\n\nCode\npay_distribution_geologist <- geologist[pay > 20000]\n\nggplot(pay_distribution_geologist, aes(job, pay)) +\n  geom_violin(aes(color=job)) +\n  geom_beeswarm(aes(color =job)) +\n  labs(title = \"Pay Distribution Between Geologists and Hydrogeologists\",\n       y = \"Yearly Salary (CAD)\")\n\n\n\n\n\n\n\n\n\nPay Distribuation by City\nThe pay distribution divided based on location including remote jobs. Cities with less than 2 or fewer job postings have been removed from the data. This plot is interactive so the cities can be selected and viewed individually.\n\n\nCode\n# remove all cities with less than two entries to clean up box plot\ncities_analyst <- pay_distribution_analyst[with(pay_distribution_analyst, location %in% names(which(table(location)>=5))), ]\n\nggplotly(ggplot(cities_analyst, aes(location, pay)) +\n  geom_boxplot(aes(color=location)) +\n  labs(title = \"Pay Distribution Between Remote and Non-Remote Jobs\",\n       y = \"Yearly Salary (CAD)\"))\n\n\n\n\n\n\n\n\nCode\n# remove all cities with less than two entries to clean up box plot\n\nggplotly(ggplot(geologist, aes(province, pay)) +\n  geom_boxplot(aes(color=province)) +\n  labs(title = \"Pay Distribution Between Remote and Non-Remote Jobs\",\n       y = \"Yearly Salary (CAD)\"))\n\n\n\n\n\n\nThis plot is not very informative due to the lack of information. For Geologist jobs, it may be more beneficial to look at the number of jobs in each city. Geology jobs are less likely to be remote and more dependant on where an individual actually wants to live\n\n\nNumber of Geologist Jobs Per City\n\n\nCode\n# remove all cities with less than two entries to clean up box plot\nggplotly(ggplot(geologist, aes(fct_infreq(location))) +\n  geom_bar(aes(color=location)) +\n  labs(title = \"Number of Geology Jobs Per City\",\n       y = \"Yearly Salary (CAD)\",\n       x = \"Location by\") +\n  theme(axis.text.x = element_blank(),\n        legend.position = \"bottom\"))"
  },
  {
    "objectID": "visualizing.html#rating-distribution",
    "href": "visualizing.html#rating-distribution",
    "title": "Visualizing Cleaned Data",
    "section": "Rating Distribution",
    "text": "Rating Distribution\n\nAll JobsData AnalystGeologist\n\n\n\n\nCode\nratings <- data[!is.na(rating)]\n\nggplot(ratings, aes(job, rating)) +\n  geom_violin(aes(color=job)) +\n  geom_jitter(aes(color=job)) +\n  labs(title = \"Rating Distribution Between Remote and Non-Remote Jobs\",\n       y = \"Yearly Salary (CAD)\")\n\n\n\n\n\n\n\n\n\nCode\nratings_analyst <- analyst[!is.na(rating)]\n\nggplot(ratings_analyst, aes(remote, rating)) +\n  geom_violin(aes(color=remote)) +\n  geom_jitter(aes(color=remote)) +\n  labs(title = \"Rating Distribution Between Remote and Non-Remote Jobs\",\n       y = \"Yearly Salary (CAD)\")\n\n\n\n\n\n\n\n\n\nCode\nratings_geologist <- geologist[!is.na(rating)]\n\nggplot(ratings_geologist, aes(job, rating)) +\n  geom_violin(aes(color=job)) +\n  geom_jitter(aes(color=job)) +\n  labs(title = \"Rating Distribution Between Remote and Non-Remote Jobs\",\n       y = \"Yearly Salary (CAD)\")"
  },
  {
    "objectID": "visualizing.html#best-companies-to-work-for-based-on-rating",
    "href": "visualizing.html#best-companies-to-work-for-based-on-rating",
    "title": "Visualizing Cleaned Data",
    "section": "Best Companies To work for Based on Rating",
    "text": "Best Companies To work for Based on Rating\nThis is a list of the best companies to work for based on rating\n\n\nCode\nkable(head(data[order(rating, decreasing=TRUE)][,c(\"company\", \"title\", \"rating\")], 20))\n\n\n\n\n\n\n\n\n\n\ncompany\ntitle\nrating\n\n\n\n\nCambium Inc.\nSenior Hydrogeologist\n5.0\n\n\nKlue\nData Analyst, Competitive Intelligence\n5.0\n\n\nCIRA\nData Analyst\n5.0\n\n\nRevolution Capital\nData Analyst\n4.8\n\n\nISG Search Inc\nSystems Analyst\n4.8\n\n\nISG Search Inc\nBusiness Analyst\n4.8\n\n\nCBCL Limited\nnewIntermediate Environmental Engineer or Scientist\n4.7\n\n\nEquation Staffing Solutions.\nnewJr Procurement Analyst (FT)\n4.7\n\n\nWorkforce Inc.\nnewCore Logging Geologist (Remote Camp)\n4.6\n\n\nWorkforce Inc.\nnewProduction Geologist\n4.6\n\n\nWorkforce Inc.\nnewResource Geologist\n4.6\n\n\nMinistÃ¨re de l’Ã‰nergie et des ressources…\nnewIngÃ©nieure ou ingÃ©nieur expert en gÃ©ologie - un poste rÃ©guli…\n4.5\n\n\nMyplanet\nData Analyst, Service Innovation\n4.5\n\n\nStackAdapt\nData Analyst, Business Intelligence (Toronto)\n4.5\n\n\nStackAdapt\nData Analyst, Inventory Partnerships (Toronto)\n4.5\n\n\nMyplanet\nBusiness Process Analyst\n4.5\n\n\nStackAdapt\nBusiness Analyst (Toronto)\n4.5\n\n\nTown of Ajax\nnewIT Project Manager & Business Analyst\n4.5\n\n\nGirl Guides of Canada-Guides du Canada\nMember Growth Analyst\n4.5\n\n\nMotoinsight\nBusiness Analyst\n4.5\n\n\n\n\n\nThis is a list of the best companies to work for based on pay\n\n\nCode\nkable(head(data[order(pay, decreasing=TRUE)][,c(\"company\", \"title\", \"pay\")], 20))\n\n\n\n\n\n\n\n\n\n\ncompany\ntitle\npay\n\n\n\n\nSoftware International\nBusiness Analyst - Incident Data (remote)\n212750\n\n\nAstraNorth\nData Analyst â€“ Power BI, SQL\n140000\n\n\nDawn InfoTek Inc.\nQuality Analyst - Data migration and ETL testing\n138750\n\n\nStelmine Canada LtÃ©e\nnewVP Exploration (GÃ©ologie)\n137500\n\n\nSLR Consulting (Canada) Ltd.\nmine geologist\n132500\n\n\nAstraNorth\nIT Data Analyst - Capital Markets\n130000\n\n\nHRC Global Services\nSAP MDM Data Analyst\n129500\n\n\nRoyal Victoria Regional Health Centre\nnewDatabase Analyst\n125800\n\n\nYork Region\nnewSenior Traffic Data Analyst (Departmental Data Analyst)\n123025\n\n\nFortisBC\nBusiness Analyst 3\n123025\n\n\nHomelessness Services Association of BC - Burnaby,…\nResearcher & Data Analyst\n120250\n\n\nSoftware International\nTechnical Business Analyst (remote)\n120250\n\n\nEPCOR\nAnalyst, Business\n120250\n\n\nDawn InfoTek Inc.\nBusiness/Data Analyst (data governance)\n120250\n\n\nCity of Edmonton\nnewStrategic Analyst\n120250\n\n\nAstraNorth\nPortfolio Data Analyst\n120000\n\n\nDynamis Capital Corp.\nMining Technologist (NOC 2212)\n119325\n\n\nRedpath Mining Contractors and Engineers\nCaribou Mine - Jumbo Operator\n114500\n\n\nSoho Square Solutions\nnewBusiness Analyst\n111000\n\n\nSLR Consulting\nSenior Hydrogeologist/Manager - Whitehorse\n110000"
  }
]